---
title: "homework 6"
uniqname: "mchenran"
format: 
  html:   
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
---

The link to my github repository: [homework 6](https://github.com/snuuym/stats506/tree/main/homework%206)

## Problem 1  
### a. 
```{r}
library(Rcpp)
library(e1071)

# Define the C++ code
cpp_code <- "
#include <Rcpp.h>
#include <cmath>
using namespace Rcpp;

// [[Rcpp::export]]
double C_moment(NumericVector v, int k) {
  double sum = 0;
  for (int i = 0; i < v.length() ; ++i){
     sum += v[i];
  }
  double mean = sum / v.length();
  
  double moment_sum = 0;
  for (int i = 0; i < v.length(); ++i){
     moment_sum += std::pow(v[i] - mean, k);
  }
  return(moment_sum / v.length());
}
"

# Compile the function
sourceCpp(code = cpp_code)

# Validation
set.seed(42)
data_vec <- rnorm(1000, mean = 50, sd = 10)
k <- 3 

res_rcpp  <- C_moment(data_vec, k)
res_e1071 <- e1071::moment(data_vec, order = k, center = TRUE)

cat("Rcpp Result:   ", res_rcpp, "\n")
cat("e1071 Result:  ", res_e1071, "\n")
```
## Problem 2  
### a. 
```{r}
library(methods)
library(parallel)
source("wald_ci.R") # Assuming this contains the parent class

# 1. Class Definition
setClass("bootstrapWaldCI",
         contains = "waldCI",
         slots = c(func = "function",     # Slot name is 'func'
                   data = "ANY",
                   reps = "numeric",
                   compute = "character") # Slot name is 'compute'
)

# 2. Helper Function
compute_selection <- function(func, data, reps, compute){
  
  n <- if (is.data.frame(data) || is.matrix(data)) nrow(data) else length(data)
  
  single_boot <- function(i) {
    indices <- sample(n, n, replace = TRUE)
    if (is.data.frame(data) || is.matrix(data)) {
      resample <- data[indices, , drop = FALSE]
    } else {
      resample <- data[indices]
    }
    return(func(resample))
  }
  
  # Compute mode
  if (compute == "serial") {
    boot_stats <- sapply(1:reps, single_boot)
  } else if (compute == "parallel") {
    # Note: mclapply works on Mac/Linux. On Windows, it falls back to serial or requires parLapply
    n_cores <- parallel::detectCores() - 1
    boot_stats <- unlist(parallel::mclapply(1:reps, single_boot, mc.cores = n_cores))
  } else {
    stop("Invalid compute mode")
  }
  
  return(sd(boot_stats, na.rm = TRUE))
}

# 3. Constructor
makeBootstrapCI <- function(stat_func, data, reps = 100, level = 0.95, compute = "serial") {
  
  original_est <- stat_func(data)
  
  # FIX 1: Swapped arguments to match definition (func, data, reps, compute)
  boot_se <- compute_selection(stat_func, data, reps, compute)
  
  # FIX 2: Used correct slot names (func, compute) matching setClass
  new("bootstrapWaldCI",
      level = level,
      mean = original_est,   
      sterr = boot_se,        
      data = data,            
      func = stat_func,       # Maps argument 'stat_func' to slot 'func'
      reps = reps,            
      compute = compute       # Maps argument 'compute' to slot 'compute'
  )
}

# 4. Rebootstrap Method
setGeneric("rebootstrap", function(object) standardGeneric("rebootstrap"))

setMethod("rebootstrap", "bootstrapWaldCI", function(object) {
  cat("Re-running bootstrap with", object@reps, "reps (", object@compute, ")...\n")
  
  # FIX 3: Swapped arguments and used correct slot names (@func, @compute)
  new_se <- compute_selection(object@func, 
                              object@data, 
                              object@reps, 
                              object@compute)
  
  object@sterr <- new_se
  return(object)
})
  
```
### b.
```{r}
ci1 <- makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000)
ci1
rebootstrap(ci1)
```
```{r}
library(microbenchmark)
bm_results <- microbenchmark(
  Serial_Mode   = makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000,
                       compute = "serial"),
  Parallel_Mode = makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000,
                       compute = "parallel"),
  times = 10,
  unit = "s" 
)

print(bm_results)
```
Parallel mode functions way more faster than serial mode
### c.   
```{r}
dispCoef <- function (data){
  model <- lm(mpg ~ cyl + disp + wt, data = data)
  return (coef(model)["disp"])
}
```

```{r}
ci2 <- makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000)
ci2
rebootstrap(ci2)
```

```{r}
bm_results <- microbenchmark(
  Serial_Mode   = makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000,
                       compute = "serial"),
  Parallel_Mode = makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000,
                       compute = "parallel"),
  times = 10,
  unit = "s" 
)

print(bm_results)
```
For this function, the difference is not as obivous as that in (b), but parallel mode still performs way faster than serial mode.

## Problem 3
### a. 
```{r}
source("data_generation.R")
df$device_type <- as.factor(df$device_type)
```

```{r}
library(lme4)
library(dplyr)
library(ggplot2)
library(parallel)

countries <- split(df, df$country)
models <- list()
running_times <- numeric()


for(country in names(countries)) {
  
  sub_data <- countries[[country]]
  
  timer <- system.time({
    
  # Standardization
  sub_data$prior_gpa_s    <- as.numeric(scale(sub_data$prior_gpa))
  sub_data$forum_posts_s  <- as.numeric(scale(sub_data$forum_posts))
  sub_data$quiz_attempts_s <- as.numeric(scale(sub_data$quiz_attempts))
    
    # Fit Mixed Effects Model

    mod <- glmer(completed_course ~ prior_gpa_s + forum_posts_s + quiz_attempts_s + (1 | device_type),
                 data = sub_data,
                 family = binomial,
                 nAGQ = 0) 
  })
  
  # Store results
  models[[country]] <- mod
  running_times[country] <- timer["elapsed"]
  
  cat(sprintf("Fitted %s: %.2f seconds\n", country, timer["elapsed"]))
}

# Report Timings
print(running_times)

# Visualization
coef_df <- data.frame(
  country = names(models),
  est = sapply(models, function(m) fixef(m)["forum_posts_s"]),
  se  = sapply(models, function(m) sqrt(diag(vcov(m)))["forum_posts_s"])
)
ggplot(coef_df, aes(x = country, y = est)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = est - 1.96*se, ymax = est + 1.96*se), width = 0.2) +
  theme_minimal()
```
### b.   
```{r}
# Parallel processing

para_processor <- function(sub_data) {
  library(lme4) 
  
  # Standardize
  sub_data$prior_gpa_s    <- as.numeric(scale(sub_data$prior_gpa))
  sub_data$forum_posts_s  <- as.numeric(scale(sub_data$forum_posts))
  sub_data$quiz_attempts_s <- as.numeric(scale(sub_data$quiz_attempts))
  
  # Fit
  glmer(completed_course ~ prior_gpa_s + forum_posts_s + quiz_attempts_s + (1 | device_type),
        data = sub_data,
        family = binomial,
        nAGQ = 0)
}


n_cores <- parallel::detectCores() - 1

total_time_opt <- system.time({
  models_par <- mclapply(countries, para_processor, mc.cores = n_cores)
  })

cat(sprintf("Total Optimized Time: %.2f seconds\n", total_time_opt["elapsed"]))

```
```{r}
# Validation
par_coefs <- sapply(models_par, function(m) fixef(m)["forum_posts_s"])
seq_coefs <- sapply(models, function(m) fixef(m)["forum_posts_s"])
all.equal(par_coefs, seq_coefs)
```

## Problem 4.     
### a.   
```{r}
library(data.table)
tennis <- fread("https://raw.githubusercontent.com/JeffSackmann/tennis_atp/refs/heads/master/atp_matches_2019.csv")
```
```{r}
#this solution is adapted from the solution of problem set 4, question 2
tourneys <- unique(tennis[, .(tourney_name)])
tourneys[, tourney_name := sub("Davis.*", "Davis Cup", tourney_name)]
tourneys <- unique(tourneys)
nrow(tourneys)
```

### b.   
```{r}
multiwinners <- tennis[order(tourney_name, -match_num), .SD[1], by = tourney_name][, .(wins = .N), by = winner_name][wins > 1][order(-wins)]
nrow(multiwinners)
multiwinners[1]
```
### c.  
```{r}
n_success <- tennis[w_ace > l_ace, .N]
n_total <- tennis[, .N]
prop.test(n_success, n_total, p = .5)
```
### d.   
```{r}
most_winners <- melt(tennis[, .(winner_name, loser_name)], 
     measure.vars = c("winner_name", "loser_name"), 
     variable.name = "outcome", 
     value.name = "player")[,
                            .(matches = .N,
                              winrate = mean(outcome == "winner_name")), by = player][
                                matches > 5
                              ][
                                order(-winrate)
                              ]

most_winners[1:2]

```
Rafael Nadal has the highest winning rate.





